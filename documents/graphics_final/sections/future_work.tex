\section{Future Work}\label{sec:futurework}
\subsection{Tracer Particles}
Mentioned in my original proposal, tracer particles
represent a powerful tool for creating visual effects.
In reality, we mostly visualize fluid flow via particles or
other objects that are carried by the fluid, like smoke or bubbles.
Utilizing tracer particles can help realize a more true-to-life
visual affect than visualizing, for example, velocity as I did in
figure \ref{fig:movie-frame}.
Using large numbers of tracer particles to generate a 
density field which is then rendered volumetrically was used to 
great effect in \cite{Li2020, Li2024, Lyu2021}.

\subsection{Zero-centered Storage}
Zero-centered storage extends the Galilean invariance of CM-MRT 
into the storage of our $f$ distributions.
It has been shown that $f_i$ don't deviate far from the reference
frame equilibrium.
By instead storing and operating on $\delta f = f - f_u$ 
I can greatly increase the numerical accuracy by better
utilizing the available bits of our floating point representation.
Zero-centered storage is thoroughly explained in \cite{Hennig2023}.
Zero-centered storage would also open the door for using a half-float 
based storage, which would be a significant improvement if viable.

\subsection{Error Aware Compiling}
Currently my code generation is quite naive, simply
templating the SymPy expressions into shader code.
However, this yeilds expressions with numerical instabilities.
For example, in summation operations it would be better to alternate
$+$ and $-$ terms in order to preserve floating point accuracy.
Symbolic manipulation improvements could lead to greater numerical 
accuracy.

\subsection{Domain Decomposition}
Right now our solver only works on a single continuous allocation
for the entire domain.
Allowing the domain to be split over many blocks would have several 
advantages.
\begin{itemize}
\item \textit{Utilizing Additional Memory } \\
My Macbook has a limit on storage buffer sizes of a little over $4$gb.
Domain decomposition would allow me to utilize more buffers, and thus more of the $64$gb I have available.

\item \textit{Distributed Computing} \\
Distributing the solve over several compute nodes would require 
domain decomposition. 
This could be multiple GPUs in one system or
multiple compute nodes in an HPC environment.

\item \text{Spatial Adaptivity} \\
Most exciting, domain decomposition would be 
the next step towards spatial adaptivity. 
Spatial adaptivity would allow the limited memory resources to
capture a greater amount of detail in turbulent flows.
\end{itemize}

